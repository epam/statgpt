# SDMX Compatibility & Requirements

This document outlines the SDMX compatibility requirements and metadata standards necessary for StatGPT to function
effectively with statistical data sources.

> **ğŸ“ Note**: StatGPT relies on the [sdmx1 library](https://github.com/khaeru/sdmx) for SDMX requests, therefore the
> requirements are dictated by what is supported in that library.

## ğŸ“Š SDMX Technical Requirements

### Version Support

| Version      | Support Level         | Notes                                            |
|--------------|-----------------------|--------------------------------------------------|
| **SDMX 2.1** | âœ… Full Support        | Complete functionality via sdmx1 library         |
| **SDMX 3.0** | âš ï¸ Restricted Support | Limited compatibility dependent on sdmx1 library |

### Format Requirements

- **Structure Endpoints**: SDMX-ML only (SDMX-JSON not supported)
- **Data Endpoints**: SDMX-ML or SDMX-JSON

### Required API Endpoints

#### Structure Endpoints

- âœ… Code Lists
- âœ… Concept Schemes
- âœ… Data Structure Definitions (DSDs)
- âœ… Dataflows

#### Data Endpoints

- âœ… Available Constraint endpoint
- âœ… Data endpoint

## ğŸŒ Connectivity Requirements

### API Availability

- **Access**: Public API availability required
- **Authentication**: No authentication or service-to-service auth supported (e.g., client credentials, basic auth, API
  key)
- **Rate Limits**: Ability to increase limits for StatGPT if they exist

### Performance Requirements

| Endpoint Type            | Request Scenario                      | Max Latency |
|--------------------------|---------------------------------------|-------------|
| **Structure**            | Single structure (no reference stubs) | < 1 sec     |
| **Data**                 | 20 series                             | < 1 sec     |
| **Available Constraint** | 300 series                            | < 1 sec     |

## ğŸ“‹ Structural Metadata Requirements

### General Requirements

All structural metadata must adhere to these standards:

1. **Localization**
    - âœ… English localizations required (minimum)
    - âœ… Additional localizations must be consistent across all structures

2. **Clarity & Precision**
    - âœ… Unambiguous, clear, and descriptive metadata
    - âœ… Context and meaning must be easily interpretable by LLM
    - âœ… Include agency ID, names, and descriptions for all artifacts

3. **Versioning**
    - âœ… Follow SDMX versioning conventions (2.1 or 3.0)
    - âœ… Ensure clarity on updates and changes

### Structure-Specific Requirements

#### ğŸ“Š Data Structure Definitions (DSDs)

**Purpose**: Define dataset structure including dimensions, attributes, and measures.

**Requirements**:

- âœ… Well-defined following SDMX best practices
- âœ… Clear component definitions with descriptive IDs
- âœ… Consistent naming conventions
- âœ… All components must have either:
    - Local representation, OR
    - Reference to a concept with specific type defined

**Component Clarity**:

- Dimensions, attributes, and measures must have IDs that clearly indicate their purpose
- Names and descriptions should be self-explanatory for LLM interpretation

#### ğŸ·ï¸ Concept Schemes

**Purpose**: Define concepts used in datasets with their relationships and meanings.

**Requirements**:

- âœ… Well-defined following SDMX best practices
- âœ… Meaningful IDs, names, and descriptions
- âœ… Clear indication of concept purpose and business meaning
- â­• Optional: Annotations for additional context

#### ğŸ“ Code Lists

**Purpose**: Essential for indexing series and providing business meaning to queries.

**Requirements**:

| Requirement                  | Description                                                  | Priority |
|------------------------------|--------------------------------------------------------------|----------|
| **Unique Names**             | Avoid duplicate names to prevent ambiguity                   | Critical |
| **Clear IDs**                | Meaningful identifiers for each code item                    | Critical |
| **Descriptions**             | Business-meaningful descriptions                             | Critical |
| **Hierarchical Consistency** | If hierarchical, must be well-defined with no contradictions | Required |
| **Annotations**              | Additional context when needed                               | Optional |

**Best Practices**:

- âš ï¸ **Avoid duplicate names** - Ambiguity makes it difficult to determine which code list item is meant in queries
- âœ… Use descriptive names that clearly indicate the item's purpose
- âœ… Maintain consistency in naming patterns across related code lists

#### ğŸ“ Dataflows

**Purpose**: Provide context about available datasets and enable dataset selection.

**Utilized Metadata**:

- Agency ID
- Dataflow ID
- Name & Description
- Version
- Annotations (when available)

**Requirements**:

- âœ… Meaningful and descriptive agency, ID, name, and description
- âœ… Clear indication of dataflow purpose
- âœ… Semantic versioning for clarity on updates
- â­• Optional: Annotations for last update date or other relevant context

## ğŸ” Metadata Quality Checklist

Use this checklist to ensure your SDMX metadata meets StatGPT requirements:

### Essential Requirements

- [ ] All metadata has English localization
- [ ] No ambiguous or duplicate names in code lists
- [ ] DSDs have clear component definitions
- [ ] Concept schemes have meaningful descriptions
- [ ] Dataflows clearly indicate their purpose
- [ ] Version numbering follows SDMX conventions

### Performance Requirements

- [ ] Structure endpoints respond in < 1 second
- [ ] Data endpoints handle 20 series in < 1 second
- [ ] Available constraint handles 300 series in < 1 second

### Connectivity Requirements

- [ ] Public API availability
- [ ] No authentication required OR service credentials available
- [ ] Rate limits adequate or increasable

## ğŸ“š Additional Resources

- [SDMX Official Documentation](https://sdmx.org/)
- [sdmx1 Library Documentation](https://github.com/khaeru/sdmx)

## âš ï¸ Common Issues to Avoid

1. **Duplicate Code List Names**: Creates ambiguity in natural language queries
2. **Missing English Localizations**: Prevents proper LLM understanding
3. **Inconsistent Hierarchies**: Causes logical contradictions in data interpretation
4. **Vague Component IDs**: Makes it difficult for LLM to understand data structure
5. **Missing Concept Definitions**: Reduces context understanding
6. **Slow API Response Times**: Degrades user experience
7. **Authentication Complexity**: Currently not supported by StatGPT

## ğŸ’¡ Recommendations for Data Providers

1. **Invest in Metadata Quality**: Clear, descriptive metadata improves StatGPT's ability to answer queries accurately
2. **Use Annotations**: Provide additional context where standard fields are insufficient
3. **Maintain Consistency**: Use the same terminology and patterns across all structures
4. **Test Performance**: Ensure your endpoints meet the latency requirements
5. **Document Special Cases**: If your implementation has unique features, document them clearly